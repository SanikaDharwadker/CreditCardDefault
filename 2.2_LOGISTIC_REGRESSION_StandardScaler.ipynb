{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook the independent variables are scaled using StandardScaler() on all features\n",
    "- We are focusing on area under precision recall curve(Higher the better)\n",
    "- Since there is a class imbalance we try solving the imbalance by hyperparameter tuning ,oversampling and smote methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import Build_Evaluate_Model as bem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBTAINING TRAIN AND TEST SET (STANDARDSCALER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=bem.get_xy_traintest(scale=True,scaler='StandardScaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_standard=bem.build_basic_model(X_train,y_train,X_test,y_test,classifier='Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.1815299983877598, 0.15970442609984317, 0.40...</td>\n",
       "      <td>[0.3738901029193777, 0.3417548278432792, 0.257...</td>\n",
       "      <td>0.77731</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.02301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MODEL                                             PARAMS  \\\n",
       "0  Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.1815299983877598, 0.15970442609984317, 0.40...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.3738901029193777, 0.3417548278432792, 0.257...      0.77731      0.7543   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0     0.02301  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASS WEIGHT PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w={0:22,1:77}\n",
    "\n",
    "log_cw=LogisticRegression(max_iter=1000,random_state=42,class_weight=w,penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_standard=bem.build_model(X_train,y_train,X_test,y_test,classifier=log_cw,classifier_name='log_cw',score_df=log_score_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.1815299983877598, 0.15970442609984317, 0.40...</td>\n",
       "      <td>[0.3738901029193777, 0.3417548278432792, 0.257...</td>\n",
       "      <td>0.777310</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.023010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4366352273221064, 0.39745337648903717, 0.70...</td>\n",
       "      <td>[0.7002594095540251, 0.6557012917693645, 0.544...</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.755057</td>\n",
       "      <td>0.022565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODEL                                             PARAMS  \\\n",
       "0   Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "1  log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.1815299983877598, 0.15970442609984317, 0.40...   \n",
       "1  [0.4366352273221064, 0.39745337648903717, 0.70...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.3738901029193777, 0.3417548278432792, 0.257...     0.777310    0.754300   \n",
       "1  [0.7002594095540251, 0.6557012917693645, 0.544...     0.777623    0.755057   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0    0.023010  \n",
       "1    0.022565  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=[{0:1.0,1:10},{0:1,1:100}, {0:1,1:150},{0:1,1:1},\n",
    "     {0:1.0,1:200},{0:1.0,1:500},{0:100,1:1000},{0:22,1:77},{0:30,1:70},{0:40,1:60},{0:20,1:80},{0:10,1:90}]\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid = {\"class_weight\": w ,'solver':['liblinear'],'penalty':['l1'],'C':c_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7706366788959484 with param: {'C': 0.1, 'class_weight': {0: 1.0, 1: 10}, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "log_search_wt=LogisticRegression(max_iter=500,random_state=42)\n",
    "\n",
    "grid = GridSearchCV(log_search_wt,hyperparam_grid,scoring=\"roc_auc\", cv=3, n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above  code gives  {'C': 0.1, 'class_weight': {0: 1.0, 1: 10}, 'penalty': 'l1', 'solver': 'liblinear'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_best_1=LogisticRegression(C= 0.1, class_weight= {0:1, 1:10}, penalty= 'l1', solver= 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_standard=bem.build_model(X_train,y_train,X_test,y_test,classifier=log_best_1,classifier_name='log_best_1',score_df=log_score_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.1815299983877598, 0.15970442609984317, 0.40...</td>\n",
       "      <td>[0.3738901029193777, 0.3417548278432792, 0.257...</td>\n",
       "      <td>0.777310</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.023010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4366352273221064, 0.39745337648903717, 0.70...</td>\n",
       "      <td>[0.7002594095540251, 0.6557012917693645, 0.544...</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.755057</td>\n",
       "      <td>0.022565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_best_1</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight={0: 1, ...</td>\n",
       "      <td>[0.6921089194560377, 0.6537096526005286, 0.872...</td>\n",
       "      <td>[0.8731732761987303, 0.8475063212196383, 0.772...</td>\n",
       "      <td>0.777600</td>\n",
       "      <td>0.755401</td>\n",
       "      <td>0.022198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MODEL                                             PARAMS  \\\n",
       "0       Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "1      log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "2  log_best_1  LogisticRegression(C=0.1, class_weight={0: 1, ...   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.1815299983877598, 0.15970442609984317, 0.40...   \n",
       "1  [0.4366352273221064, 0.39745337648903717, 0.70...   \n",
       "2  [0.6921089194560377, 0.6537096526005286, 0.872...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.3738901029193777, 0.3417548278432792, 0.257...     0.777310    0.754300   \n",
       "1  [0.7002594095540251, 0.6557012917693645, 0.544...     0.777623    0.755057   \n",
       "2  [0.8731732761987303, 0.8475063212196383, 0.772...     0.777600    0.755401   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0    0.023010  \n",
       "1    0.022565  \n",
       "2    0.022198  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7705945810426488 with param: {'C': 10, 'class_weight': {0: 1, 1: 10}, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "c_values = [10,25,35,45,50,85,100,150]\n",
    "\n",
    "hyperparam_grid = {\"class_weight\":[{0:1,1:10}] ,'solver':['liblinear'],'penalty':['l1'],'C':c_values}\n",
    "\n",
    "log_search_wt=LogisticRegression(max_iter=500,random_state=42)\n",
    "\n",
    "grid = GridSearchCV(log_search_wt,hyperparam_grid,scoring=\"roc_auc\", cv=3, n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score: 0.7705945810426488 with param: {'C': 10, 'class_weight': {0: 1, 1: 10}, 'penalty': 'l1', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_best_2=LogisticRegression(C= 10, class_weight= {0:1, 1:10}, penalty= 'l1', solver= 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_standard=bem.build_model(X_train,y_train,X_test,y_test,classifier=log_best_2,classifier_name='log_best_2',score_df=log_score_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.1815299983877598, 0.15970442609984317, 0.40...</td>\n",
       "      <td>[0.3738901029193777, 0.3417548278432792, 0.257...</td>\n",
       "      <td>0.777310</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.023010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4366352273221064, 0.39745337648903717, 0.70...</td>\n",
       "      <td>[0.7002594095540251, 0.6557012917693645, 0.544...</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.755057</td>\n",
       "      <td>0.022565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_best_1</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight={0: 1, ...</td>\n",
       "      <td>[0.6921089194560377, 0.6537096526005286, 0.872...</td>\n",
       "      <td>[0.8731732761987303, 0.8475063212196383, 0.772...</td>\n",
       "      <td>0.777600</td>\n",
       "      <td>0.755401</td>\n",
       "      <td>0.022198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_best_2</td>\n",
       "      <td>LogisticRegression(C=10, class_weight={0: 1, 1...</td>\n",
       "      <td>[0.6913220094781583, 0.6537217142891872, 0.874...</td>\n",
       "      <td>[0.877489793337063, 0.8479177492863919, 0.7721...</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.755371</td>\n",
       "      <td>0.022252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MODEL                                             PARAMS  \\\n",
       "0       Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "1      log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "2  log_best_1  LogisticRegression(C=0.1, class_weight={0: 1, ...   \n",
       "3  log_best_2  LogisticRegression(C=10, class_weight={0: 1, 1...   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "0  [0.1815299983877598, 0.15970442609984317, 0.40...   \n",
       "1  [0.4366352273221064, 0.39745337648903717, 0.70...   \n",
       "2  [0.6921089194560377, 0.6537096526005286, 0.872...   \n",
       "3  [0.6913220094781583, 0.6537217142891872, 0.874...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "0  [0.3738901029193777, 0.3417548278432792, 0.257...     0.777310    0.754300   \n",
       "1  [0.7002594095540251, 0.6557012917693645, 0.544...     0.777623    0.755057   \n",
       "2  [0.8731732761987303, 0.8475063212196383, 0.772...     0.777600    0.755401   \n",
       "3  [0.877489793337063, 0.8479177492863919, 0.7721...     0.777623    0.755371   \n",
       "\n",
       "   DIFFERENCE  \n",
       "0    0.023010  \n",
       "1    0.022565  \n",
       "2    0.022198  \n",
       "3    0.022252  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_score_minmax=bem.build_ensemble(X_train,y_train,X_test,y_test,classifier_name='log_standard',score_df=log_score_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PARAMS</th>\n",
       "      <th>y_train_prob</th>\n",
       "      <th>y_test_prob</th>\n",
       "      <th>TRAIN SCORE</th>\n",
       "      <th>TEST SCORE</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_best_1</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight={0: 1, ...</td>\n",
       "      <td>[0.6921089194560377, 0.6537096526005286, 0.872...</td>\n",
       "      <td>[0.8731732761987303, 0.8475063212196383, 0.772...</td>\n",
       "      <td>0.777600</td>\n",
       "      <td>0.755401</td>\n",
       "      <td>0.022198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log_best_2</td>\n",
       "      <td>LogisticRegression(C=10, class_weight={0: 1, 1...</td>\n",
       "      <td>[0.6913220094781583, 0.6537217142891872, 0.874...</td>\n",
       "      <td>[0.877489793337063, 0.8479177492863919, 0.7721...</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.755371</td>\n",
       "      <td>0.022252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_cw</td>\n",
       "      <td>LogisticRegression(class_weight={0: 22, 1: 77}...</td>\n",
       "      <td>[0.4366352273221064, 0.39745337648903717, 0.70...</td>\n",
       "      <td>[0.7002594095540251, 0.6557012917693645, 0.544...</td>\n",
       "      <td>0.777623</td>\n",
       "      <td>0.755057</td>\n",
       "      <td>0.022565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log_standard_ensemble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.5003990386610155, 0.466147292369649, 0.7150...</td>\n",
       "      <td>[0.706203145502299, 0.6732200475296685, 0.5867...</td>\n",
       "      <td>0.777705</td>\n",
       "      <td>0.755093</td>\n",
       "      <td>0.022612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>LogisticRegression(max_iter=500, random_state=42)</td>\n",
       "      <td>[0.1815299983877598, 0.15970442609984317, 0.40...</td>\n",
       "      <td>[0.3738901029193777, 0.3417548278432792, 0.257...</td>\n",
       "      <td>0.777310</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.023010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MODEL                                             PARAMS  \\\n",
       "2             log_best_1  LogisticRegression(C=0.1, class_weight={0: 1, ...   \n",
       "3             log_best_2  LogisticRegression(C=10, class_weight={0: 1, 1...   \n",
       "1                 log_cw  LogisticRegression(class_weight={0: 22, 1: 77}...   \n",
       "4  log_standard_ensemble                                                NaN   \n",
       "0                  Basic  LogisticRegression(max_iter=500, random_state=42)   \n",
       "\n",
       "                                        y_train_prob  \\\n",
       "2  [0.6921089194560377, 0.6537096526005286, 0.872...   \n",
       "3  [0.6913220094781583, 0.6537217142891872, 0.874...   \n",
       "1  [0.4366352273221064, 0.39745337648903717, 0.70...   \n",
       "4  [0.5003990386610155, 0.466147292369649, 0.7150...   \n",
       "0  [0.1815299983877598, 0.15970442609984317, 0.40...   \n",
       "\n",
       "                                         y_test_prob  TRAIN SCORE  TEST SCORE  \\\n",
       "2  [0.8731732761987303, 0.8475063212196383, 0.772...     0.777600    0.755401   \n",
       "3  [0.877489793337063, 0.8479177492863919, 0.7721...     0.777623    0.755371   \n",
       "1  [0.7002594095540251, 0.6557012917693645, 0.544...     0.777623    0.755057   \n",
       "4  [0.706203145502299, 0.6732200475296685, 0.5867...     0.777705    0.755093   \n",
       "0  [0.3738901029193777, 0.3417548278432792, 0.257...     0.777310    0.754300   \n",
       "\n",
       "   DIFFERENCE  \n",
       "2    0.022198  \n",
       "3    0.022252  \n",
       "1    0.022565  \n",
       "4    0.022612  \n",
       "0    0.023010  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score_minmax.sort_values(by='DIFFERENCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our best model for logistic using standard scaler is log_best_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
